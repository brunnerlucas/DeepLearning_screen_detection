# ğŸ¯ DeepLearning Screen Detection

A real-time screen watching detection system with desktop, web, and mobile camera interfaces using pose estimation (YOLOv11) and gaze detection (MediaPipe)

> **ğŸ“± Mobile Camera**: Uses HTTPS for reliable camera access. The system processes your phone's camera feed locally using AI models for real-time gaze and pose detection.

## ğŸ“ Project Structure

```
DeepLearning_screen_detection/
â”œâ”€â”€ ğŸ“± web/                     # Mobile camera application
â”‚   â”œâ”€â”€ web_app_https.py       # HTTPS mobile server
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html         # html code for frontend
â”‚   â”œâ”€â”€ qr_code_https.png      # QR code
â”œâ”€â”€ ğŸ§ª main/                    # WIP: Initial logic and prototyping
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ ğŸ“š Archive/                # Legacy code
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ run_mobile_https.sh       # HTTPS mobile launcher (recommended)
â”œâ”€â”€ run_mobile_https.ps1      # Windows launcher script
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

```

## ğŸš€ Quick Start

### 1. Setup Environment
```bash
git clone https://github.com/YOUR_USERNAME/DeepLearning_screen_detection.git
cd DeepLearning_screen_detection

# Create and activate virtual environment
python3 -m venv screenwatch-venv
source screenwatch-venv/bin/activate  # On Windows: screenwatch-venv\Scripts\activate

# Install dependencies
pip install --upgrade pip
pip install -r requirements.txt
```
### 2. Run the Code
```bash
source screenwatch-venv/bin/activate

# On Mac/Linux
chmod +x run_mobile_https.sh
./run_mobile_https.sh

# On Windows
.\run_mobile_https.ps1

```
### Mobile Usage
1. **QR Code**: Scan the generated `qr_code_https.png` with your phone
2. **Camera Permissions**: Allow camera access when prompted
3. **Detection**: Point camera at your face while looking at phone screen
4. **Alert**: If a second person watches your screen an alert should pop up





